{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import Popen, PIPE\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sent: b'{\"action_id\":0,\"params\":[14,10]}\\n'\n",
      "recieved: \n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-9e019be09d0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-9e019be09d0b>\u001b[0m in \u001b[0;36msend\u001b[0;34m(p, s)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sent:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "p = Popen(['../cpp_backend/cmake-build-debug/cpp_backend'], shell=True, stdout=PIPE, stdin=PIPE)\n",
    "\n",
    "def send(p, s):\n",
    "    p.stdin.write(s)\n",
    "    p.stdin.flush()\n",
    "    print(\"sent:\", s)\n",
    "\n",
    "    line = p.stdout.readline()\n",
    "    result = line.decode(\"utf-8\") \n",
    "    print(\"recieved:\", result)\n",
    "\n",
    "    return result \n",
    "\n",
    "for i in range(100):\n",
    "    a_id = 0\n",
    "    a1 = np.random.randint(20)\n",
    "    a2 = np.random.randint(20)\n",
    "    \n",
    "    def get_q(): return '{\"action_id\":'+str(a_id)+',\"params\":[' + str(a1) + ',' + str(a2) + ']}\\n' \n",
    "    q = get_q()\n",
    "    q = str.encode(q)\n",
    "    \n",
    "    send(p, q)\n",
    "    \n",
    "line = p.stdout.readline()\n",
    "result = line.decode(\"utf-8\") \n",
    "print(result)\n",
    "\n",
    "p.kill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_attr=[1444, 1], edge_index=[2, 1444], test_mask=[570], train_mask=[570], val_mask=[570], x=[570, 1], y=[570])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "with open('../cpp_backend/cmake-build-debug/graph.json') as f:\n",
    "    j = json.loads(''.join(f.readlines()))\n",
    "\n",
    "def construct_data(j):\n",
    "    # Data(edge_index=[2, 10556], test_mask=[2708], train_mask=[2708], val_mask=[2708], x=[2708, 1433], y=[2708])\n",
    "    \n",
    "    num_edges = len(j['e'])\n",
    "    num_vertices = len(j['v'])\n",
    "    \n",
    "    d = Data() \n",
    "    d.edge_index = torch.zeros(2, num_edges).long()\n",
    "    d.train_mask = torch.zeros(num_vertices).bool()\n",
    "    d.test_mask = torch.zeros(num_vertices).bool()\n",
    "    d.val_mask = torch.zeros(num_vertices).bool()\n",
    "    d.edge_attr = torch.zeros(num_edges, 1).float()\n",
    "    \n",
    "    d.x = torch.zeros(num_vertices, 1).float()\n",
    "    d.y = torch.zeros(num_vertices).long()\n",
    "    \n",
    "    \n",
    "    for i, (id, tag, _) in enumerate(j['v']):\n",
    "        d.x[id] = 0\n",
    "        d.y[id] = tag\n",
    "        \n",
    "        d.train_mask[id] = (id % 3) == 0 \n",
    "        d.val_mask[id] = (id % 3) == 1 \n",
    "        d.test_mask[id] = (id % 3) == 2\n",
    "        \n",
    "    for i, (v, u, tag) in enumerate(j['e']):\n",
    "        d.edge_index[0][i] = v\n",
    "        d.edge_index[1][i] = u\n",
    "        d.edge_attr[i][0] = tag\n",
    "        \n",
    "    return d\n",
    "\n",
    "d = construct_data(j)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005, Train: 0.8105, Val: 0.7579, Test: 0.8105 Loss: 0.5589\n",
      "Epoch: 010, Train: 0.8105, Val: 0.7632, Test: 0.8158 Loss: 0.4891\n",
      "Epoch: 015, Train: 0.8105, Val: 0.7632, Test: 0.8158 Loss: 0.4835\n",
      "Epoch: 020, Train: 0.8105, Val: 0.7632, Test: 0.8158 Loss: 0.4716\n",
      "Epoch: 025, Train: 0.8105, Val: 0.7632, Test: 0.8158 Loss: 0.4528\n",
      "Epoch: 030, Train: 0.8105, Val: 0.7632, Test: 0.8158 Loss: 0.4313\n",
      "Epoch: 035, Train: 0.8105, Val: 0.7684, Test: 0.8158 Loss: 0.4075\n",
      "Epoch: 040, Train: 0.8474, Val: 0.8158, Test: 0.8368 Loss: 0.3814\n",
      "Epoch: 045, Train: 0.8579, Val: 0.8316, Test: 0.8421 Loss: 0.3567\n",
      "Epoch: 050, Train: 0.8526, Val: 0.8368, Test: 0.8368 Loss: 0.3330\n",
      "Epoch: 055, Train: 0.8684, Val: 0.8421, Test: 0.8474 Loss: 0.3146\n",
      "Epoch: 060, Train: 0.8737, Val: 0.8474, Test: 0.8474 Loss: 0.3032\n",
      "Epoch: 065, Train: 0.8737, Val: 0.8579, Test: 0.8684 Loss: 0.2936\n",
      "Epoch: 070, Train: 0.8789, Val: 0.8579, Test: 0.8684 Loss: 0.2841\n",
      "Epoch: 075, Train: 0.8895, Val: 0.8632, Test: 0.8737 Loss: 0.2741\n",
      "Epoch: 080, Train: 0.8947, Val: 0.8684, Test: 0.8842 Loss: 0.2628\n",
      "Epoch: 085, Train: 0.9000, Val: 0.8737, Test: 0.8842 Loss: 0.2509\n",
      "Epoch: 090, Train: 0.9053, Val: 0.8789, Test: 0.8842 Loss: 0.2386\n",
      "Epoch: 095, Train: 0.9211, Val: 0.8842, Test: 0.9000 Loss: 0.2262\n",
      "Epoch: 100, Train: 0.9211, Val: 0.8895, Test: 0.9053 Loss: 0.2142\n",
      "Epoch: 105, Train: 0.9316, Val: 0.8947, Test: 0.9105 Loss: 0.2031\n",
      "Epoch: 110, Train: 0.9316, Val: 0.8947, Test: 0.9105 Loss: 0.1932\n",
      "Epoch: 115, Train: 0.9316, Val: 0.8947, Test: 0.9158 Loss: 0.1845\n",
      "Epoch: 120, Train: 0.9368, Val: 0.9053, Test: 0.9158 Loss: 0.1770\n",
      "Epoch: 125, Train: 0.9474, Val: 0.9211, Test: 0.9263 Loss: 0.1705\n",
      "Epoch: 130, Train: 0.9474, Val: 0.9263, Test: 0.9263 Loss: 0.1650\n",
      "Epoch: 135, Train: 0.9474, Val: 0.9368, Test: 0.9316 Loss: 0.1603\n",
      "Epoch: 140, Train: 0.9526, Val: 0.9421, Test: 0.9316 Loss: 0.1562\n",
      "Epoch: 145, Train: 0.9526, Val: 0.9474, Test: 0.9421 Loss: 0.1526\n",
      "Epoch: 150, Train: 0.9526, Val: 0.9474, Test: 0.9421 Loss: 0.1494\n",
      "Epoch: 155, Train: 0.9526, Val: 0.9474, Test: 0.9421 Loss: 0.1465\n",
      "Epoch: 160, Train: 0.9526, Val: 0.9474, Test: 0.9421 Loss: 0.1438\n",
      "Epoch: 165, Train: 0.9579, Val: 0.9474, Test: 0.9474 Loss: 0.1413\n",
      "Epoch: 170, Train: 0.9579, Val: 0.9474, Test: 0.9474 Loss: 0.1389\n",
      "Epoch: 175, Train: 0.9579, Val: 0.9474, Test: 0.9474 Loss: 0.1365\n",
      "Epoch: 180, Train: 0.9579, Val: 0.9474, Test: 0.9474 Loss: 0.1342\n",
      "Epoch: 185, Train: 0.9579, Val: 0.9474, Test: 0.9474 Loss: 0.1319\n",
      "Epoch: 190, Train: 0.9632, Val: 0.9632, Test: 0.9684 Loss: 0.1296\n",
      "Epoch: 195, Train: 0.9632, Val: 0.9632, Test: 0.9684 Loss: 0.1273\n",
      "Epoch: 200, Train: 0.9632, Val: 0.9632, Test: 0.9684 Loss: 0.1249\n",
      "Epoch: 205, Train: 0.9632, Val: 0.9632, Test: 0.9684 Loss: 0.1225\n",
      "Epoch: 210, Train: 0.9632, Val: 0.9632, Test: 0.9684 Loss: 0.1201\n",
      "Epoch: 215, Train: 0.9632, Val: 0.9632, Test: 0.9684 Loss: 0.1177\n",
      "Epoch: 220, Train: 0.9632, Val: 0.9632, Test: 0.9684 Loss: 0.1152\n",
      "Epoch: 225, Train: 0.9632, Val: 0.9632, Test: 0.9684 Loss: 0.1126\n",
      "Epoch: 230, Train: 0.9632, Val: 0.9632, Test: 0.9684 Loss: 0.1100\n",
      "Epoch: 235, Train: 0.9632, Val: 0.9632, Test: 0.9684 Loss: 0.1074\n",
      "Epoch: 240, Train: 0.9632, Val: 0.9632, Test: 0.9684 Loss: 0.1047\n",
      "Epoch: 245, Train: 0.9632, Val: 0.9632, Test: 0.9684 Loss: 0.1019\n",
      "Epoch: 250, Train: 0.9684, Val: 0.9789, Test: 0.9789 Loss: 0.0991\n",
      "Epoch: 255, Train: 0.9684, Val: 0.9789, Test: 0.9789 Loss: 0.0963\n",
      "Epoch: 260, Train: 0.9684, Val: 0.9789, Test: 0.9789 Loss: 0.0934\n",
      "Epoch: 265, Train: 0.9684, Val: 0.9789, Test: 0.9789 Loss: 0.0904\n",
      "Epoch: 270, Train: 0.9684, Val: 0.9789, Test: 0.9789 Loss: 0.0874\n",
      "Epoch: 275, Train: 0.9684, Val: 0.9789, Test: 0.9789 Loss: 0.0843\n",
      "Epoch: 280, Train: 0.9684, Val: 0.9789, Test: 0.9789 Loss: 0.0812\n",
      "Epoch: 285, Train: 0.9737, Val: 0.9789, Test: 0.9842 Loss: 0.0780\n",
      "Epoch: 290, Train: 0.9737, Val: 0.9789, Test: 0.9842 Loss: 0.0748\n",
      "Epoch: 295, Train: 0.9737, Val: 0.9789, Test: 0.9842 Loss: 0.0715\n",
      "Epoch: 300, Train: 0.9737, Val: 0.9789, Test: 0.9842 Loss: 0.0682\n",
      "Epoch: 305, Train: 0.9737, Val: 0.9789, Test: 0.9842 Loss: 0.0650\n",
      "Epoch: 310, Train: 0.9737, Val: 0.9789, Test: 0.9842 Loss: 0.0617\n",
      "Epoch: 315, Train: 0.9737, Val: 0.9789, Test: 0.9842 Loss: 0.0585\n",
      "Epoch: 320, Train: 0.9737, Val: 0.9789, Test: 0.9842 Loss: 0.0554\n",
      "Epoch: 325, Train: 0.9737, Val: 0.9789, Test: 0.9842 Loss: 0.0524\n",
      "Epoch: 330, Train: 0.9737, Val: 0.9789, Test: 0.9842 Loss: 0.0496\n",
      "Epoch: 335, Train: 0.9789, Val: 0.9789, Test: 0.9842 Loss: 0.0469\n",
      "Epoch: 340, Train: 0.9789, Val: 0.9789, Test: 0.9842 Loss: 0.0445\n",
      "Epoch: 345, Train: 0.9789, Val: 0.9789, Test: 0.9842 Loss: 0.0422\n",
      "Epoch: 350, Train: 0.9789, Val: 0.9789, Test: 0.9842 Loss: 0.0402\n",
      "Epoch: 355, Train: 0.9789, Val: 0.9789, Test: 0.9842 Loss: 0.0383\n",
      "Epoch: 360, Train: 0.9789, Val: 0.9789, Test: 0.9842 Loss: 0.0367\n",
      "Epoch: 365, Train: 0.9789, Val: 0.9789, Test: 0.9842 Loss: 0.0351\n",
      "Epoch: 370, Train: 0.9789, Val: 0.9789, Test: 0.9842 Loss: 0.0337\n",
      "Epoch: 375, Train: 0.9789, Val: 0.9789, Test: 0.9842 Loss: 0.0324\n",
      "Epoch: 380, Train: 0.9789, Val: 0.9789, Test: 0.9842 Loss: 0.0311\n",
      "Epoch: 385, Train: 0.9789, Val: 0.9789, Test: 0.9842 Loss: 0.0300\n",
      "Epoch: 390, Train: 0.9789, Val: 0.9789, Test: 0.9842 Loss: 0.0288\n",
      "Epoch: 395, Train: 0.9789, Val: 0.9789, Test: 0.9842 Loss: 0.0278\n",
      "Epoch: 400, Train: 0.9789, Val: 0.9789, Test: 0.9842 Loss: 0.0267\n",
      "Epoch: 405, Train: 0.9789, Val: 0.9789, Test: 0.9842 Loss: 0.0257\n",
      "Epoch: 410, Train: 0.9789, Val: 0.9789, Test: 0.9842 Loss: 0.0247\n",
      "Epoch: 415, Train: 0.9789, Val: 0.9789, Test: 0.9842 Loss: 0.0237\n",
      "Epoch: 420, Train: 0.9789, Val: 0.9789, Test: 0.9842 Loss: 0.0228\n",
      "Epoch: 425, Train: 0.9789, Val: 0.9789, Test: 0.9842 Loss: 0.0219\n",
      "Epoch: 430, Train: 0.9789, Val: 0.9789, Test: 0.9842 Loss: 0.0210\n",
      "Epoch: 435, Train: 0.9842, Val: 0.9842, Test: 0.9895 Loss: 0.0201\n",
      "Epoch: 440, Train: 1.0000, Val: 0.9895, Test: 1.0000 Loss: 0.0193\n",
      "Epoch: 445, Train: 1.0000, Val: 0.9895, Test: 1.0000 Loss: 0.0184\n",
      "Epoch: 450, Train: 1.0000, Val: 0.9895, Test: 1.0000 Loss: 0.0176\n",
      "Epoch: 455, Train: 1.0000, Val: 0.9895, Test: 1.0000 Loss: 0.0168\n",
      "Epoch: 460, Train: 1.0000, Val: 0.9895, Test: 1.0000 Loss: 0.0160\n",
      "Epoch: 465, Train: 1.0000, Val: 0.9895, Test: 1.0000 Loss: 0.0152\n",
      "Epoch: 470, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0145\n",
      "Epoch: 475, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0137\n",
      "Epoch: 480, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0129\n",
      "Epoch: 485, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0121\n",
      "Epoch: 490, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0114\n",
      "Epoch: 495, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0107\n",
      "Epoch: 500, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0100\n",
      "Epoch: 505, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0093\n",
      "Epoch: 510, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0087\n",
      "Epoch: 515, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0081\n",
      "Epoch: 520, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0075\n",
      "Epoch: 525, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0069\n",
      "Epoch: 530, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0064\n",
      "Epoch: 535, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0059\n",
      "Epoch: 540, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0055\n",
      "Epoch: 545, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0051\n",
      "Epoch: 550, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0048\n",
      "Epoch: 555, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0045\n",
      "Epoch: 560, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0042\n",
      "Epoch: 565, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0040\n",
      "Epoch: 570, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0038\n",
      "Epoch: 575, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0036\n",
      "Epoch: 580, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0034\n",
      "Epoch: 585, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0033\n",
      "Epoch: 590, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0032\n",
      "Epoch: 595, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0030\n",
      "Epoch: 600, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0029\n",
      "Epoch: 605, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0028\n",
      "Epoch: 610, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0028\n",
      "Epoch: 615, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0027\n",
      "Epoch: 620, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0026\n",
      "Epoch: 625, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0025\n",
      "Epoch: 630, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0025\n",
      "Epoch: 635, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0024\n",
      "Epoch: 640, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0024\n",
      "Epoch: 645, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0023\n",
      "Epoch: 650, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0023\n",
      "Epoch: 655, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0022\n",
      "Epoch: 660, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0022\n",
      "Epoch: 665, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0021\n",
      "Epoch: 670, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0021\n",
      "Epoch: 675, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0021\n",
      "Epoch: 680, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0020\n",
      "Epoch: 685, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0020\n",
      "Epoch: 690, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0020\n",
      "Epoch: 695, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0019\n",
      "Epoch: 700, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0019\n",
      "Epoch: 705, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0019\n",
      "Epoch: 710, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0019\n",
      "Epoch: 715, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0018\n",
      "Epoch: 720, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0018\n",
      "Epoch: 725, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0018\n",
      "Epoch: 730, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0018\n",
      "Epoch: 735, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0017\n",
      "Epoch: 740, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0017\n",
      "Epoch: 745, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0017\n",
      "Epoch: 750, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0017\n",
      "Epoch: 755, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0016\n",
      "Epoch: 760, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0016\n",
      "Epoch: 765, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0016\n",
      "Epoch: 770, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0016\n",
      "Epoch: 775, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0016\n",
      "Epoch: 780, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0015\n",
      "Epoch: 785, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0015\n",
      "Epoch: 790, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0015\n",
      "Epoch: 795, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0015\n",
      "Epoch: 800, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0015\n",
      "Epoch: 805, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0015\n",
      "Epoch: 810, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0014\n",
      "Epoch: 815, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0014\n",
      "Epoch: 820, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0014\n",
      "Epoch: 825, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0014\n",
      "Epoch: 830, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0014\n",
      "Epoch: 835, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0014\n",
      "Epoch: 840, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0014\n",
      "Epoch: 845, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0013\n",
      "Epoch: 850, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0013\n",
      "Epoch: 855, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0013\n",
      "Epoch: 860, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0013\n",
      "Epoch: 865, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0013\n",
      "Epoch: 870, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0013\n",
      "Epoch: 875, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0013\n",
      "Epoch: 880, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0012\n",
      "Epoch: 885, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0012\n",
      "Epoch: 890, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0012\n",
      "Epoch: 895, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0012\n",
      "Epoch: 900, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0012\n",
      "Epoch: 905, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0012\n",
      "Epoch: 910, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0012\n",
      "Epoch: 915, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0012\n",
      "Epoch: 920, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0011\n",
      "Epoch: 925, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0011\n",
      "Epoch: 930, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0011\n",
      "Epoch: 935, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0011\n",
      "Epoch: 940, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0011\n",
      "Epoch: 945, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0011\n",
      "Epoch: 950, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0011\n",
      "Epoch: 955, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0011\n",
      "Epoch: 960, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0011\n",
      "Epoch: 965, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0010\n",
      "Epoch: 970, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0010\n",
      "Epoch: 975, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0010\n",
      "Epoch: 980, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0010\n",
      "Epoch: 985, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0010\n",
      "Epoch: 990, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0010\n",
      "Epoch: 995, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0010\n",
      "Epoch: 1000, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0010\n",
      "Epoch: 1005, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0010\n",
      "Epoch: 1010, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0010\n",
      "Epoch: 1015, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0010\n",
      "Epoch: 1020, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0009\n",
      "Epoch: 1025, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0009\n",
      "Epoch: 1030, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0009\n",
      "Epoch: 1035, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0009\n",
      "Epoch: 1040, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0009\n",
      "Epoch: 1045, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0009\n",
      "Epoch: 1050, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0009\n",
      "Epoch: 1055, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0009\n",
      "Epoch: 1060, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0009\n",
      "Epoch: 1065, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0009\n",
      "Epoch: 1070, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0009\n",
      "Epoch: 1075, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0009\n",
      "Epoch: 1080, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0009\n",
      "Epoch: 1085, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0008\n",
      "Epoch: 1090, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0008\n",
      "Epoch: 1095, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0008\n",
      "Epoch: 1100, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0008\n",
      "Epoch: 1105, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0008\n",
      "Epoch: 1110, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0008\n",
      "Epoch: 1115, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0008\n",
      "Epoch: 1120, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0008\n",
      "Epoch: 1125, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0008\n",
      "Epoch: 1130, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0008\n",
      "Epoch: 1135, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0008\n",
      "Epoch: 1140, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0008\n",
      "Epoch: 1145, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0008\n",
      "Epoch: 1150, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0008\n",
      "Epoch: 1155, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0008\n",
      "Epoch: 1160, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0007\n",
      "Epoch: 1165, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0007\n",
      "Epoch: 1170, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0007\n",
      "Epoch: 1175, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0007\n",
      "Epoch: 1180, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0007\n",
      "Epoch: 1185, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0007\n",
      "Epoch: 1190, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0007\n",
      "Epoch: 1195, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0007\n",
      "Epoch: 1200, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0007\n",
      "Epoch: 1205, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0007\n",
      "Epoch: 1210, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0007\n",
      "Epoch: 1215, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0007\n",
      "Epoch: 1220, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0007\n",
      "Epoch: 1225, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0007\n",
      "Epoch: 1230, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0007\n",
      "Epoch: 1235, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0007\n",
      "Epoch: 1240, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0007\n",
      "Epoch: 1245, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0007\n",
      "Epoch: 1250, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0006\n",
      "Epoch: 1255, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0006\n",
      "Epoch: 1260, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0006\n",
      "Epoch: 1265, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0006\n",
      "Epoch: 1270, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0006\n",
      "Epoch: 1275, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0006\n",
      "Epoch: 1280, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0006\n",
      "Epoch: 1285, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0006\n",
      "Epoch: 1290, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0006\n",
      "Epoch: 1295, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0006\n",
      "Epoch: 1300, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0006\n",
      "Epoch: 1305, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0006\n",
      "Epoch: 1310, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0006\n",
      "Epoch: 1315, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0006\n",
      "Epoch: 1320, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0006\n",
      "Epoch: 1325, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0006\n",
      "Epoch: 1330, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0006\n",
      "Epoch: 1335, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0006\n",
      "Epoch: 1340, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0006\n",
      "Epoch: 1345, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0006\n",
      "Epoch: 1350, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0006\n",
      "Epoch: 1355, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0006\n",
      "Epoch: 1360, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0006\n",
      "Epoch: 1365, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0005\n",
      "Epoch: 1370, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0005\n",
      "Epoch: 1375, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0005\n",
      "Epoch: 1380, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0005\n",
      "Epoch: 1385, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0005\n",
      "Epoch: 1390, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0005\n",
      "Epoch: 1395, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0005\n",
      "Epoch: 1400, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0005\n",
      "Epoch: 1405, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0005\n",
      "Epoch: 1410, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0005\n",
      "Epoch: 1415, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0005\n",
      "Epoch: 1420, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0005\n",
      "Epoch: 1425, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0005\n",
      "Epoch: 1430, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0005\n",
      "Epoch: 1435, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0005\n",
      "Epoch: 1440, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0005\n",
      "Epoch: 1445, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0005\n",
      "Epoch: 1450, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0005\n",
      "Epoch: 1455, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0005\n",
      "Epoch: 1460, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0005\n",
      "Epoch: 1465, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0005\n",
      "Epoch: 1470, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0005\n",
      "Epoch: 1475, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0005\n",
      "Epoch: 1480, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0005\n",
      "Epoch: 1485, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0005\n",
      "Epoch: 1490, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0005\n",
      "Epoch: 1495, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0005\n",
      "Epoch: 1500, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0005\n",
      "Epoch: 1505, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0005\n",
      "Epoch: 1510, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0004\n",
      "Epoch: 1515, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0004\n",
      "Epoch: 1520, Train: 1.0000, Val: 0.9947, Test: 1.0000 Loss: 0.0004\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-e719002974df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Epoch: {:03d}, Train: {:.4f}, Val: {:.4f}, Test: {:.4f}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-e719002974df>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-e719002974df>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# x = self.lin(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/research/glasperlenspiel/models/cg_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;34m\"\"\"\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0medge_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_j\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, size, dim, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmessage_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscatter_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mupdate_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/torch_geometric/utils/scatter.py\u001b[0m in \u001b[0;36mscatter_\u001b[0;34m(name, src, index, dim, dim_size)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch_scatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'scatter_{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch_scatter/add.py\u001b[0m in \u001b[0;36mscatter_add\u001b[0;34m(src, index, dim, out, dim_size, fill_value)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \"\"\"\n\u001b[1;32m     74\u001b[0m     \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter_add_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, MessagePassing\n",
    "from cg_conv import CGConv\n",
    "\n",
    "data = construct_data(j)\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # self.conv1 = GATConv(1, 2, heads=1, dropout=0.0)\n",
    "        \n",
    "        self.lin1 = torch.nn.Linear(1, 4)\n",
    "        \n",
    "        self.conv1 = CGConv(channels=4, dim=1)\n",
    "        self.conv2 = CGConv(channels=4, dim=1)\n",
    "        \n",
    "        # self.conv2 = GATConv(1, 4, heads=1, concat=True, dropout=0.6)\n",
    "        self.lin2 = torch.nn.Linear(4, 2)\n",
    "        \n",
    "        # self.conv2 = GATConv(1, 4, heads=1, concat=True, dropout=0.6)\n",
    "\n",
    "    def forward(self):\n",
    "        x = data.x\n",
    "        # x = F.dropout(data.x, p=0.2, training=self.training)\n",
    "        # x = F.leaky_relu(self.conv1(x, data.edge_index, data.edge_attr))\n",
    "        # x = self.lin(x) \n",
    "        x = self.lin1(x)\n",
    "        x = self.conv1(x, data.edge_index, data.edge_attr)\n",
    "        x = self.conv2(x, data.edge_index, data.edge_attr)\n",
    "        x = self.lin2(x)\n",
    "        # x = F.dropout(x, p=0.6, training=self.training)\n",
    "        # x = self.conv2(x, data.edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "device = torch.device('cpu')\n",
    "model, data = Net().to(device), data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=4e-3, weight_decay=1e-5)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    loss = F.nll_loss(model()[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.detach().numpy()\n",
    "\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    logits, accs = model(), []\n",
    "    for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n",
    "        # print(logits)\n",
    "        pred = logits[mask].max(1)[1]\n",
    "        acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
    "        accs.append(acc)\n",
    "    return accs\n",
    "\n",
    "\n",
    "for epoch in range(1, 5000):\n",
    "    loss = train()\n",
    "    log = 'Epoch: {:03d}, Train: {:.4f}, Val: {:.4f}, Test: {:.4f}'\n",
    "    if epoch % 5 == 0:\n",
    "        print(log.format(epoch, *test()) + ' Loss: {:.4f}'.format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
